# ğŸ“š Examples

This directory contains examples showing how to use the Ollama Native library.

## ğŸš€ API Generation Examples

### ğŸ”§ Basic Examples
- **`basic.ts`** - Basic text generation with streaming and non-streaming modes
- **`fill-in-middle.ts`** - Code completion and fill-in-the-middle scenarios

### ğŸ§  Thinking Examples
- **`thinking-bool.ts`** - Boolean thinking mode for yes/no questions and logical reasoning
- **`thinking-gpt.ts`** - GPT-style thinking with different levels (low, medium, high) for complex problem solving

### â¹ï¸ Abort Examples
- **`abort-manual.ts`** - Manual request abortion using the abort() method
- **`abort-timing.ts`** - Timing-based request abortion with setTimeout

## â–¶ï¸ Running Examples

1. ğŸ”Œ Ensure Ollama is running on `http://localhost:11434`
2. ğŸ“¥ Install required models:
   ```bash
   ollama pull qwen3:1.7b
   ollama pull qwen2.5-coder:1.5b
   ollama pull gpt-oss:20b-cloud
   ```
3. ğŸƒ Run examples:
   ```bash
   npx tsx examples/api-generate/basic.ts
   npx tsx examples/api-generate/fill-in-middle.ts
   npx tsx examples/api-generate/thinking-bool.ts
   npx tsx examples/api-generate/thinking-gpt.ts
   npx tsx examples/api-generate/abort-manual.ts
   npx tsx examples/api-generate/abort-timing.ts
   ```

### ğŸ”„ Retry Mechanism

- The retry mechanism runs automatically when network errors occur (timeout, connection refused, server errors). It uses exponential backoff (1s â†’ 2s â†’ 4s) and only retries on retryable errors. See implementation: [`src/services/Fetch.ts`](../src/services/Fetch.ts#L89-L94)